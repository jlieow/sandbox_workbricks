{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63bbe4f2-77c0-4d74-b551-5616ddf13828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 55714)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/socketserver.py\", line 318, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.12/socketserver.py\", line 349, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.12/socketserver.py\", line 362, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/conda/lib/python3.12/socketserver.py\", line 766, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 299, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 271, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 275, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/serializers.py\", line 597, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.appName('Transforms').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54c722da-2236-4e19-a614-d072e0b316a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| user| book|\n",
      "+-----+-----+\n",
      "|user1|book1|\n",
      "|user1|book2|\n",
      "|user2|book2|\n",
      "|user2|book4|\n",
      "|user3|book1|\n",
      "+-----+-----+\n",
      "\n",
      "+-----+------------------+\n",
      "| user|collect_list(book)|\n",
      "+-----+------------------+\n",
      "|user1|    [book1, book2]|\n",
      "|user2|    [book2, book4]|\n",
      "|user3|           [book1]|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# collect_list\n",
    "\n",
    "data = [('user1','book1'),\n",
    "        ('user1','book2'),\n",
    "        ('user2','book2'),\n",
    "        ('user2','book4'),\n",
    "        ('user3','book1')]\n",
    "\n",
    "schema = 'user string, book string'\n",
    "\n",
    "df_book = spark.createDataFrame(data,schema)\n",
    "\n",
    "df_book.show()\n",
    "\n",
    "df_book.groupBy('user').agg(collect_list('book')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4b778e8-37c6-40f4-88b5-765d32f265b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------+\n",
      "|           Item_Type|Outlet_Size|Item_MRP|\n",
      "+--------------------+-----------+--------+\n",
      "|               Dairy|     Medium|249.8092|\n",
      "|         Soft Drinks|     Medium| 48.2692|\n",
      "|                Meat|     Medium| 141.618|\n",
      "|Fruits and Vegeta...|       NULL| 182.095|\n",
      "|           Household|       High| 53.8614|\n",
      "|        Baking Goods|     Medium| 51.4008|\n",
      "|         Snack Foods|       High| 57.6588|\n",
      "|         Snack Foods|     Medium|107.7622|\n",
      "|        Frozen Foods|       NULL| 96.9726|\n",
      "|        Frozen Foods|       NULL|187.8214|\n",
      "|Fruits and Vegeta...|     Medium| 45.5402|\n",
      "|               Dairy|      Small|144.1102|\n",
      "|Fruits and Vegeta...|     Medium|145.4786|\n",
      "|         Snack Foods|      Small|119.6782|\n",
      "|Fruits and Vegeta...|       High|196.4426|\n",
      "|           Breakfast|      Small| 56.3614|\n",
      "|  Health and Hygiene|     Medium|115.3492|\n",
      "|           Breakfast|     Medium| 54.3614|\n",
      "|         Hard Drinks|     Medium|113.2834|\n",
      "|               Dairy|      Small|230.5352|\n",
      "+--------------------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "+--------------------+------------------+------------------+------------------+------------------+\n",
      "|           Item_Type|              null|              High|            Medium|             Small|\n",
      "+--------------------+------------------+------------------+------------------+------------------+\n",
      "|       Starchy Foods|140.48000465116277|158.15707368421053| 148.4195041666666| 150.2701736842105|\n",
      "|              Breads|139.04861666666667|         133.75896| 140.8610385542169| 145.5236507042254|\n",
      "|        Baking Goods|126.66939891891889|129.20204383561642|126.17856847290639|125.21336363636368|\n",
      "|Fruits and Vegeta...|142.57516045845267|145.57287042253515| 142.9714702179177|148.31336951219507|\n",
      "|                Meat|139.29453448275865| 137.2447902439025|136.41913154362408|145.69925042016808|\n",
      "|         Hard Drinks| 134.3875333333333| 141.9275217391304|142.83769599999994|        129.758784|\n",
      "|         Soft Drinks|133.42344360902257|131.75847346938772| 128.2696817518248| 132.8550428571429|\n",
      "|           Household|147.76930421455944|147.09752233009704|147.71133010380618| 153.9654389105058|\n",
      "|           Breakfast| 158.6750903225807|147.49058461538462|134.53751111111112|130.56802666666667|\n",
      "|               Dairy| 149.0512677419355|153.50917249999995|148.51217431192666|145.94210101010103|\n",
      "|         Snack Foods| 145.0097524096384|145.84708639999994|148.77919509803917|144.35189611940308|\n",
      "|              Others|132.59299565217393|       132.5766125|127.83618076923078|137.88921090909088|\n",
      "|             Seafood|142.21686666666668|134.86424000000002|  140.857619047619|         144.28176|\n",
      "|              Canned|140.65181123595508| 135.4427076923077|138.12485069124423|142.29542857142857|\n",
      "|        Frozen Foods|137.49448464730293|         136.82925|140.55701532846714|137.83854377510033|\n",
      "|  Health and Hygiene|130.55989019607844|135.11098032786884|128.70186470588237|131.83153529411757|\n",
      "+--------------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PIVOT\n",
    "\n",
    "df = spark.read.format('csv').option('inferSchema',True).option('header',True).load('BigMart_Sales.csv')\n",
    "\n",
    "df.select(col('Item_Type'), col('Outlet_Size'), col('Item_MRP')).show()\n",
    "\n",
    "df.groupBy('Item_Type').pivot('Outlet_Size').agg(avg('Item_MRP')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b71840d9-92a1-48b4-bd86-d22347825a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|           Item_Type|veg_flag|\n",
      "+--------------------+--------+\n",
      "|               Dairy|     Veg|\n",
      "|         Soft Drinks|     Veg|\n",
      "|                Meat| Non-Veg|\n",
      "|Fruits and Vegeta...|     Veg|\n",
      "|           Household|     Veg|\n",
      "|        Baking Goods|     Veg|\n",
      "|         Snack Foods|     Veg|\n",
      "|         Snack Foods|     Veg|\n",
      "|        Frozen Foods|     Veg|\n",
      "|        Frozen Foods|     Veg|\n",
      "|Fruits and Vegeta...|     Veg|\n",
      "|               Dairy|     Veg|\n",
      "|Fruits and Vegeta...|     Veg|\n",
      "|         Snack Foods|     Veg|\n",
      "|Fruits and Vegeta...|     Veg|\n",
      "|           Breakfast|     Veg|\n",
      "|  Health and Hygiene|     Veg|\n",
      "|           Breakfast|     Veg|\n",
      "|         Hard Drinks|     Veg|\n",
      "|               Dairy|     Veg|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "+--------------------+--------+---------------+\n",
      "|           Item_Type|veg_flag|   veg_exp_flag|\n",
      "+--------------------+--------+---------------+\n",
      "|               Dairy|     Veg|  Veg_Expensive|\n",
      "|         Soft Drinks|     Veg|Veg_Inexpensive|\n",
      "|                Meat| Non-Veg|        Non_Veg|\n",
      "|Fruits and Vegeta...|     Veg|  Veg_Expensive|\n",
      "|           Household|     Veg|Veg_Inexpensive|\n",
      "|        Baking Goods|     Veg|Veg_Inexpensive|\n",
      "|         Snack Foods|     Veg|Veg_Inexpensive|\n",
      "|         Snack Foods|     Veg|  Veg_Expensive|\n",
      "|        Frozen Foods|     Veg|Veg_Inexpensive|\n",
      "|        Frozen Foods|     Veg|  Veg_Expensive|\n",
      "|Fruits and Vegeta...|     Veg|Veg_Inexpensive|\n",
      "|               Dairy|     Veg|  Veg_Expensive|\n",
      "|Fruits and Vegeta...|     Veg|  Veg_Expensive|\n",
      "|         Snack Foods|     Veg|  Veg_Expensive|\n",
      "|Fruits and Vegeta...|     Veg|  Veg_Expensive|\n",
      "|           Breakfast|     Veg|Veg_Inexpensive|\n",
      "|  Health and Hygiene|     Veg|  Veg_Expensive|\n",
      "|           Breakfast|     Veg|Veg_Inexpensive|\n",
      "|         Hard Drinks|     Veg|  Veg_Expensive|\n",
      "|               Dairy|     Veg|  Veg_Expensive|\n",
      "+--------------------+--------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# When-Otherwise\n",
    "\n",
    "df = spark.read.format('csv').option('inferSchema',True).option('header',True).load('BigMart_Sales.csv')\n",
    "df = df.withColumn('veg_flag',when(col('Item_Type')=='Meat','Non-Veg').otherwise('Veg'))\n",
    "\n",
    "df.select(col('Item_Type'), col('veg_flag')).show()\n",
    "\n",
    "df = df.withColumn('veg_exp_flag',when(((col('veg_flag')=='Veg') & (col('Item_MRP')<100)),'Veg_Inexpensive')\\\n",
    "                            .when((col('veg_flag')=='Veg') & (col('Item_MRP')>100),'Veg_Expensive')\\\n",
    "                            .otherwise('Non_Veg'))\n",
    "\n",
    "df.select(col('Item_Type'), col('veg_flag'), col('veg_exp_flag')).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
